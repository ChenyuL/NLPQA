#!/usr/bin/env python3


import logging
import sys
import os
import subprocess
import shutil
from haystack.utils import convert_files_to_docs, clean_wiki_text
from haystack.nodes import FARMReader
from nltk.corpus import wordnet
import spacy
import warnings
warnings.filterwarnings("ignore")

DEBUG = True
USE_LOCAL_MODELS = True
### Check the current environment has all packages we need
import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"

def checkEnvironment():
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'spaCy==3.4'], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'nltk==3.7'], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)
    subprocess.check_call([sys.executable, '-m', 'pip', 'install',  'farm-haystack==1.10.0'], stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)
    return

######## get semantic negation for similarity calculation
def Negation(sentence):
  '''
  Input: Tokenized sentence (List of words)
  Output: Tokenized sentence with negation handled (List of words)
  '''
  temp = int(0)
  for i in range(len(sentence)):
      if sentence[i-1] in ['not',"n't"]:
          antonyms = []
          for syn in wordnet.synsets(sentence[i]):
              syns = wordnet.synsets(sentence[i])
              w1 = syns[0].name()
              temp = 0
              for l in syn.lemmas():
                  if l.antonyms():
                      antonyms.append(l.antonyms()[0].name())
              max_dissimilarity = 0
              for ant in antonyms:
                  syns = wordnet.synsets(ant)
                  w2 = syns[0].name()
                  syns = wordnet.synsets(sentence[i])
                  w1 = syns[0].name()
                  word1 = wordnet.synset(w1)
                  word2 = wordnet.synset(w2)
                  if isinstance(word1.wup_similarity(word2), float) or isinstance(word1.wup_similarity(word2), int):
                      temp = 1 - word1.wup_similarity(word2)
                  if temp>max_dissimilarity:
                      max_dissimilarity = temp
                      antonym_max = ant
                      sentence[i] = antonym_max
                      sentence[i-1] = ''
  while '' in sentence:
      sentence.remove('')
  return sentence

def isYesNoQuestion(question):
    s = question.lower()
    prefixes = ['am','is','are',"was","were", "wasn't", "weren't",
                "do","does","did","doesn't","didn't",
                "has","have","hasn't", "haven't","had",
                "can","could","will","would","may","might","shall","must","should"] # reference https://englishstudypage.com/grammar/yesno-questions/
    result = s.startswith(tuple(prefixes))
    return result

def answerWHQuestion(question,file):

    #### set document folder

    docs = convert_files_to_docs(dir_path=filePath, clean_func=clean_wiki_text, split_paragraphs=False)

    # retriever = BM25Retriever(document_store = document_store)
    reader = FARMReader(model_name_or_path = "deepset/roberta-base-squad2", use_gpu=True)
    prediction = reader.predict(
        query=question,
        documents = docs,
        top_k=1
    )

    answer = prediction['answers'][0].to_dict()['answer']
    # print(answer)
    return answer



def answerYesNoQuestion(question,file):

    docs = convert_files_to_docs(dir_path=file, clean_func=clean_wiki_text, split_paragraphs=False)
    # retriever = BM25Retriever(document_store = document_store)
    reader = FARMReader(model_name_or_path = "deepset/roberta-base-squad2", use_gpu=True)
    prediction = reader.predict(
        query=question,
        documents = docs,
        top_k=1
    )

    nlp = spacy.load('en_core_web_sm')
    queryTokens = nlp(question)

    ## get 1st predict score and answer
    score = prediction['answers'][0].to_dict()['score']
    answer = prediction['answers'][0].to_dict()['answer']
    answerTokens = nlp(answer)
    sentence_tokens = [[token.text for token in sent] for sent in answerTokens.sents]

    ### add sentence semantic negation
    negateTokens = Negation(sentence_tokens)
    answerNegateSentence = ' '.join(map(str, negateTokens))
    answerNegate = nlp(answerNegateSentence)

    QAsimilarityNegate = queryTokens.similarity(answerNegate)

    QAsimilarity = queryTokens.similarity(answerTokens)  # need to test the QAsimilarity constrain, current useless

    if ((score >= 0.5) ==True) & ((QAsimilarityNegate >0.15) == True):  ## 0.15 from experiment
        answerYN = "Yes"
    else:
        answerYN = "No"

    return answerYN

if __name__ == "__main__":

    # ignore sterr and stdout
    try:
        checkEnvironment()
    except:
        print("environment Error, please check")

    if DEBUG == False:
        sys.stderr = open('/dev/null', 'w')

    try:
        # if (len(sys.argv) == 2):
        txt_input_file = sys.argv[1]
        # print(txt_input_file)
        questionFile = sys.argv[2]
        if (os.path.exists('saveDocs')==True):
            shutil.rmtree('saveDocs')
            os.mkdir('saveDocs')
        else:
            os.mkdir('saveDocs')

        shutil.copy(txt_input_file, 'saveDocs')
        filePath = str("./saveDocs")

        with open(questionFile) as f:
            questions = f.readlines()
            cnt = 1
            answers = []
            for i in range(len(questions)):

                if isYesNoQuestion(questions[i]) :
                    answer = answerYesNoQuestion(questions[i],filePath)###
                    # print("test answer", answer)
                    answers.append(answer)
                else:
                    answer = answerWHQuestion(questions[i],filePath)  ### need to edit file folder here, file is a folder contains .txt files
                    # print("test answer", answer)
                    answers.append(answer)

    ############## get the output format #################
            # print("***************************")
            # print("A1 ", answers[1])
            # print("A2 ", answers[2])
            # print("A3 ", answers[3])
            for i in range(len(answers)): # ask professor how many questions will be asked ?
                # print("A{}".format(i), answers[i])
                print(answers[i])
    except:

        print("Error: This script requires two arguments: (1) article.txt (2) question.txt ")


