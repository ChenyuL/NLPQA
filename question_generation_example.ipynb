{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChenyuL/NLPQA/blob/main/question_generation_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37NoGAv01Rpf"
      },
      "source": [
        "# Question Generator example\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Qdbnz0o3t_z",
        "outputId": "60553db1-a590-4ea2-fd6d-603870923f7c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nSVh6loD4TU-",
        "outputId": "e1dd4c6c-f4db-4af4-b8ce-56169bd297de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r '/content/drive/MyDrive/11611NatrualLanguageProcessingProject/' '/content'\n",
        "!cd 11611NatrualLanguageProcessingProject"
      ],
      "metadata": {
        "id": "2zIhaZ2H4KAr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp5OXQIYr75w"
      },
      "source": [
        "First we need to install HuggingFace's transformers library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUHut4M46Q4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f2f3352-1d3d-4635-926d-1d2d7c14e65b"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.0-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (5.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 33.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.0-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.0 tokenizers-0.13.1 transformers-4.23.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 2.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWov3aAB1fv9"
      },
      "source": [
        "Next we have to clone the github repo and import `questiongenerator`:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khOAtlkGhlCV",
        "outputId": "44a07d00-ced4-43c7-b93a-276cda146c2d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAv5Pn9s1qxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe859e4d-8ac9-45c5-a4ea-b55b7795ea84"
      },
      "source": [
        "!git clone https://github.com/amontgomerie/question_generator/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'question_generator'...\n",
            "remote: Enumerating objects: 252, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 252 (delta 42), reused 40 (delta 39), pack-reused 188\u001b[K\n",
            "Receiving objects: 100% (252/252), 114.54 KiB | 1.11 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1b3VfOMEBMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6d24ad-90ef-42d6-adc4-b0d1a99dfabe"
      },
      "source": [
        "%cd question_generator/\n",
        "%load questiongenerator.py\n",
        "from questiongenerator import QuestionGenerator\n",
        "from questiongenerator import print_qa"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/question_generator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8W1Wg6a252c"
      },
      "source": [
        "Make sure that we're using the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vORCXExB899M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "19b32ce1-00f9-42e3-d7e8-074974aec25e"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "assert device == torch.device('cuda'), \"Not using CUDA. Set: Runtime > Change runtime type > Hardware Accelerator: GPU\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9d58b518c006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Not using CUDA. Set: Runtime > Change runtime type > Hardware Accelerator: GPU\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: Not using CUDA. Set: Runtime > Change runtime type > Hardware Accelerator: GPU"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqtaLDlkdP2-"
      },
      "source": [
        "\n",
        "Now we can create a `QuestionGenerator` and feed it some text. We are going to use a BBC article about Twitter getting hacked.\n",
        "\n",
        "The models should be automatically loaded when instantiating the `QuestionGenerator` class, but if you have them saved somewhere else you can pass the path to the folder containing them as an argument like `QuestionGenerator(MODEL_DIR)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_uS3hEw9ONQ"
      },
      "source": [
        "qg = QuestionGenerator()\n",
        "\n",
        "with open('articles/Portuguese_language.txt', 'r') as a:\n",
        "    article = a.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cyay8xh1Q4O"
      },
      "source": [
        "Now We can call `QuestionGenerator`'s `generate()` method. We can choose an answer style from `['all', 'sentences', 'multiple_choice']`. \n",
        "\n",
        "You can choose how many questions you want to generate by setting `num_questions`. Note that the quality of questions may decrease if `num_questions` is high.\n",
        "\n",
        "If you just want to print the questions without showing the answers, you can optionally set `show_answers=False` when calling `print_qa()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rdEZNtzgSLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fdf4f61-afe1-40bb-97e3-5ae26c118228"
      },
      "source": [
        "qa_list = qg.generate(\n",
        "    article, \n",
        "    num_questions=10, \n",
        "    answer_style='sentences',\n",
        "    use_evaluator=True\n",
        ")\n",
        "print_qa(qa_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating questions...\n",
            "\n",
            "Evaluating QA pairs...\n",
            "\n",
            "1) Q: What is the pronunciation of a uvular fricative trill in Lisbon?\n",
            "   A: A common realization of the word-initial /r/ in the Lisbon accent is a voiced uvular fricative trill [].\n",
            "\n",
            "2) Q: Why was the Galician language on the verge of disappearing?\n",
            "   A: As reported by UNESCO, due to the pressure of Spanish on the standard official version of Galician and centuries-old Hispanization, the Galician language was on the verge of disappearing.\n",
            "\n",
            "3) Q: What is the pronunciation of a uvular trill in Portugal?\n",
            "   A: In Europe, it is typically a uvular trill []; however, a pronunciation as a voiced uvular fricative [] may be becoming dominant in urban areas.\n",
            "\n",
            "4) Q: How many countries will include Portuguese in the school curriculum by 2020?\n",
            "   A: Also, according to Portugal's Minister of Foreign Affairs, the language will be part of the school curriculum of a total of 32 countries by 2020.\n",
            "\n",
            "5) Q: What is the difference between /s and z?\n",
            "   A: /s/ and /z/ are normally lamino-alveolar, as in English.\n",
            "\n",
            "6) Q: What is the pronunciation of the consonant hereafter denoted as?\n",
            "   A: The consonant hereafter denoted as // has a variety of realizations depending on dialect.\n",
            "\n",
            "7) Q: What languages have Portuguese received a steady influx of loanwords from?\n",
            "   A: Finally, it has received a steady influx of loanwords from other European languages, especially French and English.\n",
            "\n",
            "8) Q: What is the main difference between the dialects of time and of profession?\n",
            "   A: Also Contador d'Argote (1725) distinguishes three main varieties of dialects: the local dialects, the dialects of time, and of profession (work jargon).\n",
            "\n",
            "9) Q: What is the difference between the dialects of Beira and Estremadura?\n",
            "   A: The dialectal diversity becomes more evident in the work of Ferno d'Oliveira, in the Grammatica da Lingoagem Portuguesa, (1536), where he remarks that the people of Portuguese regions of Beira, Alentejo, Estremadura, and Entre Douro e Minho, all speak differently from each other.\n",
            "\n",
            "10) Q: What is the difference between apical and laminal sibilants?\n",
            "    A: A very few northeastern Portugal dialects still maintain the medieval distinction between apical and laminal sibilants (written s/ss and c/ç/z, respectively).\n",
            "\n"
          ]
        }
      ]
    }
  ]
}